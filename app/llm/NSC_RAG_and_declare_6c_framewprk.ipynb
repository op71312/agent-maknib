{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gTApYtSpUJsF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "054e02fa-da0f-486d-cc5c-5faced0b8163"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install sentence-transformers\n",
        "!pip install attacut\n",
        "!pip install scikit-learn\n",
        "!pip install faiss-cpu\n"
      ],
      "metadata": {
        "id": "1uGi-8dOR75R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2784fc88-7aa1-48cf-b307-3dba8a13b69f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.53.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.6.15)\n",
            "Requirement already satisfied: attacut in /usr/local/lib/python3.11/dist-packages (1.0.6)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from attacut) (0.6.2)\n",
            "Requirement already satisfied: fire>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from attacut) (0.7.0)\n",
            "Requirement already satisfied: nptyping>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from attacut) (2.5.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from attacut) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.1.2 in /usr/local/lib/python3.11/dist-packages (from attacut) (6.0.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from attacut) (1.17.0)\n",
            "Requirement already satisfied: ssg>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from attacut) (0.0.8)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from attacut) (2.6.0+cu124)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire>=0.1.3->attacut) (3.1.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.9.6 in /usr/local/lib/python3.11/dist-packages (from ssg>=0.0.4->attacut) (0.9.11)\n",
            "Requirement already satisfied: tqdm>=4.32.2 in /usr/local/lib/python3.11/dist-packages (from ssg>=0.0.4->attacut) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->attacut) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->attacut) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->attacut) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->attacut) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->attacut) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->attacut) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->attacut) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->attacut) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->attacut) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->attacut) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->attacut) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->attacut) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->attacut) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->attacut) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->attacut) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->attacut) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->attacut) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->attacut) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->attacut) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->attacut) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.2.0->attacut) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.2.0->attacut) (3.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import attacut\n",
        "import faiss\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ],
      "metadata": {
        "id": "9J8nieiWhlec"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Initialize Models\n",
        "print(\"Initializing models...\")\n",
        "# Initialize SentenceTransformer (ใช้โมเดลที่รองรับภาษาไทย)\n",
        "model = SentenceTransformer('Qwen/Qwen3-Embedding-0.6B')\n",
        "\n",
        "# Test AttaCut (no need to load model, it's automatic)\n",
        "print(\"Testing AttaCut...\")\n",
        "test_tokens = attacut.tokenize(\"ทดสอบการตัดคำภาษาไทย\")\n",
        "print(f\"AttaCut test result: {test_tokens}\")\n",
        "\n",
        "print(\"Models initialized successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EByln1pdqP-u",
        "outputId": "0ef29336-7ee6-4def-d16b-8300a7e6e082"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing models...\n",
            "Testing AttaCut...\n",
            "AttaCut test result: ['ทดสอบ', 'การ', 'ตัด', 'คำ', 'ภาษา', 'ไทย']\n",
            "Models initialized successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Data Loading\n",
        "def load_data(file_path='/content/drive/MyDrive/AlphaZero_Backups/data/36strategies-description.csv'):\n",
        "    \"\"\"\n",
        "    เตรียมข้อมูล - อ่านไฟล์ CSV\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        print(f\"Data loaded successfully! Shape: {df.shape}\")\n",
        "        print(f\"Columns: {df.columns.tolist()}\")\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File {file_path} not found\")\n",
        "        return None\n",
        "\n",
        "# Load data\n",
        "df = load_data()\n",
        "if df is not None:\n",
        "    print(\"\\nFirst few rows:\")\n",
        "    print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dSl5Ol-QD6T",
        "outputId": "7ce16176-6fd4-4901-e2e5-c6643a8ddcde"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully! Shape: (36, 5)\n",
            "Columns: ['ชื่อกลยุทธ์', 'หมวด', 'ลักษณะ', 'ตัวอย่างกลยุทธ์', 'ตัวอย่างการเดินหมาก']\n",
            "\n",
            "First few rows:\n",
            "        ชื่อกลยุทธ์    หมวด  \\\n",
            "0    ปิดฟ้าข้ามทะเล  ชนะศึก   \n",
            "1  ล้อมเว่ยช่วยจ้าว  ชนะศึก   \n",
            "2       ยืมดาบฆ่าคน  ชนะศึก   \n",
            "3    รอซ้ำยามเปลี้ย  ชนะศึก   \n",
            "4       ชิงซ้ำตามไฟ  ชนะศึก   \n",
            "\n",
            "                                              ลักษณะ  \\\n",
            "0  กลยุทธ์นี้เกี่ยวข้องกับการทำสิ่งใดสิ่งหนึ่งอย่...   \n",
            "1  กลยุทธ์นี้มีความหมายว่าศัตรูได้รวบรวมกำลังทหาร...   \n",
            "2  หมายถึงการกำจัดศัตรูที่มีความเข้มแข็ง ไม่จำเป็...   \n",
            "3  หมายถึงการที่ศัตรูยังคงมีความเข้มแข็ง กำลังไพร...   \n",
            "4  หมายถึงการที่ศัตรูยังคงมีสภาพที่อ่อนแอและย่ำแย...   \n",
            "\n",
            "                                     ตัวอย่างกลยุทธ์  \\\n",
            "0  การนำเอากลยุทธ์ \"ปิดฟ้าข้ามทะเล\" ถูกใช้โดยลกซุ...   \n",
            "1  การนำเอา \"กลยุทธ์ล้อมเว่ยช่วยจ้าว\" ไปใช้ได้แก่...   \n",
            "2  การนำเอากลยุทธ์ยืมดาบฆ่าคนไปใช้ได้แก่ จิวยี่ที...   \n",
            "3  การนำเอากลยุทธ์รอช้าตามเปลี่ยนไปใช้ได้แก่ ลกซุ...   \n",
            "4  การนำเอากลยุทธ์ชิงซ้ำตามไฟไปใช้ได้แก่ ตังโต๊ะท...   \n",
            "\n",
            "                                 ตัวอย่างการเดินหมาก  \n",
            "0  เดินหมากหนึ่งก้าวตรงหน้าให้ดูธรรมดา แล้วแอบเตร...  \n",
            "1  พอคู่ต่อสู้เน้นมาซ้อนหมากตรงจุดหนึ่ง เราก็ขยับ...  \n",
            "2  รอให้คู่ต่อสู้เดินผิดกลางกระดาน แล้ววิ่งหมากเข...  \n",
            "3  ปล่อยให้คู่ต่อสู้เดินขยับจนเหนื่อย แล้วค่อยเดิ...  \n",
            "4  เห็นคู่ต่อสู้กำลังวุ่นกับหมากกลุ่มหนึ่ง ก็รีบเ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Semantic Chunking Functions\n",
        "def split_sentences(text):\n",
        "    \"\"\"\n",
        "    Split text into sentences using regex or AttaCut\n",
        "    \"\"\"\n",
        "    # Thai sentence ending patterns\n",
        "    sentence_endings = r'[.!?。๏\\n]+'\n",
        "    sentences = re.split(sentence_endings, text)\n",
        "    sentences = [s.strip() for s in sentences if s.strip()]\n",
        "\n",
        "    # If no sentences found, use AttaCut\n",
        "    if len(sentences) <= 1:\n",
        "        words = attacut.tokenize(text)\n",
        "        # Group words into sentences (simple approach)\n",
        "        sentences = []\n",
        "        current_sentence = \"\"\n",
        "        for word in words:\n",
        "            current_sentence += word\n",
        "            if len(current_sentence) > 100:  # Arbitrary length\n",
        "                sentences.append(current_sentence.strip())\n",
        "                current_sentence = \"\"\n",
        "        if current_sentence:\n",
        "            sentences.append(current_sentence.strip())\n",
        "\n",
        "    return sentences\n",
        "\n",
        "def compute_sentence_embeddings(sentences):\n",
        "    \"\"\"\n",
        "    Compute embeddings for sentences\n",
        "    \"\"\"\n",
        "    if not sentences:\n",
        "        return np.array([])\n",
        "    return model.encode(sentences)\n",
        "\n",
        "def calculate_cosine_similarity(embeddings):\n",
        "    \"\"\"\n",
        "    Calculate cosine similarity between consecutive embeddings\n",
        "    \"\"\"\n",
        "    if len(embeddings) <= 1:\n",
        "        return []\n",
        "\n",
        "    similarities = []\n",
        "    for i in range(len(embeddings) - 1):\n",
        "        sim = np.dot(embeddings[i], embeddings[i+1]) / (\n",
        "            np.linalg.norm(embeddings[i]) * np.linalg.norm(embeddings[i+1])\n",
        "        )\n",
        "        similarities.append(sim)\n",
        "\n",
        "    return similarities\n",
        "\n",
        "def determine_breakpoints(similarities, percentile=95):\n",
        "    \"\"\"\n",
        "    Determine breakpoints using percentile threshold\n",
        "    \"\"\"\n",
        "    if not similarities:\n",
        "        return []\n",
        "\n",
        "    threshold = np.percentile(similarities, percentile)\n",
        "    breakpoints = []\n",
        "    for i, sim in enumerate(similarities):\n",
        "        if sim < threshold:\n",
        "            breakpoints.append(i + 1)  # +1 because we want to break after current sentence\n",
        "\n",
        "    return breakpoints\n",
        "\n",
        "def create_chunks(sentences, breakpoints):\n",
        "    \"\"\"\n",
        "    Create chunks based on breakpoints\n",
        "    \"\"\"\n",
        "    if not sentences:\n",
        "        return []\n",
        "\n",
        "    chunks = []\n",
        "    start = 0\n",
        "\n",
        "    for breakpoint in breakpoints:\n",
        "        if breakpoint > start:\n",
        "            chunk = \" \".join(sentences[start:breakpoint])\n",
        "            chunks.append(chunk)\n",
        "            start = breakpoint\n",
        "\n",
        "    # Add remaining sentences as last chunk\n",
        "    if start < len(sentences):\n",
        "        chunk = \" \".join(sentences[start:])\n",
        "        chunks.append(chunk)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def semantic_chunking(text, percentile=95):\n",
        "    \"\"\"\n",
        "    Complete semantic chunking pipeline\n",
        "    \"\"\"\n",
        "    sentences = split_sentences(text)\n",
        "    if len(sentences) <= 1:\n",
        "        return [text]\n",
        "\n",
        "    embeddings = compute_sentence_embeddings(sentences)\n",
        "    similarities = calculate_cosine_similarity(embeddings)\n",
        "    breakpoints = determine_breakpoints(similarities, percentile)\n",
        "    chunks = create_chunks(sentences, breakpoints)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Test semantic chunking\n",
        "test_text = \"นี่คือประโยคแรกมันพูดถึงเรื่องหนึ่งประโยคที่สองพูดถึงเรื่องที่เกี่ยวข้องแต่ประโยคที่สามเปลี่ยนหัวข้อไปคุยเรื่องอื่นมันไม่เกี่ยวข้องกับเรื่องเดิม\"\n",
        "chunks = semantic_chunking(test_text)\n",
        "print(\"Test chunks:\", chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOQJz3Wuq_3D",
        "outputId": "c174dff8-28e9-41b2-e1fc-c4ddec164fd4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test chunks: ['นี่คือประโยคแรกมันพูดถึงเรื่องหนึ่งประโยคที่สองพูดถึงเรื่องที่เกี่ยวข้องแต่ประโยคที่สามเปลี่ยนหัวข้อไป คุยเรื่องอื่นมันไม่เกี่ยวข้องกับเรื่องเดิม']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Process All Strategies into Chunks\n",
        "def process_all_strategies(df):\n",
        "    \"\"\"\n",
        "    Process all strategies into chunks\n",
        "    \"\"\"\n",
        "    if df is None:\n",
        "        return []\n",
        "\n",
        "    all_chunks = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        strategy_name = row['ชื่อกลยุทธ์']\n",
        "\n",
        "        # Combine description and example (including new Go example)\n",
        "        full_text = f\"{row['ลักษณะ']} {row['ตัวอย่างกลยุทธ์']}\"\n",
        "\n",
        "        # Add Go example if available\n",
        "        if 'ตัวอย่างการเดินหมาก' in row and pd.notna(row['ตัวอย่างการเดินหมาก']):\n",
        "            full_text += f\" {row['ตัวอย่างการเดินหมาก']}\"\n",
        "\n",
        "        # Create chunks\n",
        "        chunks = semantic_chunking(full_text)\n",
        "\n",
        "        # Add metadata to chunks\n",
        "        for chunk in chunks:\n",
        "            all_chunks.append({\n",
        "                'strategy_name': strategy_name,\n",
        "                'category': row['หมวด'],\n",
        "                'chunk_text': chunk,\n",
        "                'full_text': full_text,\n",
        "                'go_example': row.get('ตัวอย่างการเดินหมาก', '') if pd.notna(row.get('ตัวอย่างการเดินหมาก', '')) else ''\n",
        "            })\n",
        "\n",
        "    return all_chunks\n",
        "\n",
        "# Process all strategies\n",
        "all_chunks = process_all_strategies(df)\n",
        "print(f\"Total chunks created: {len(all_chunks)}\")\n",
        "if all_chunks:\n",
        "    for i, chunk in enumerate(all_chunks[:3]):  # Show first 3 chunks\n",
        "        print(f\"Chunk {i+1}: {chunk['strategy_name']} - {chunk['chunk_text'][:100]}...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qRkljXRrCjk",
        "outputId": "84b29f87-a02c-44e1-e09d-4179e7ef72c8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total chunks created: 424\n",
            "Chunk 1: ปิดฟ้าข้ามทะเล - กลยุทธ์นี้เกี่ยวข้องกับการทำสิ่งใดสิ่งหนึ่งอย่างเปิดเผยในขณะที่แอบเตรียมการอื่น ๆ มักจะเกิดขึ้นเมื่อ...\n",
            "Chunk 2: ปิดฟ้าข้ามทะเล - ยิ่งเมื่อต้องโจมตีศัตรูที่แข็งแกร่งและเตรียมพร้อม หรือเมื่อเผชิญหน้ากับศัตรูที่ทรงพลังเป็นครั้งแรก ม...\n",
            "Chunk 3: ปิดฟ้าข้ามทะเล - เกี่ยวข้องกับการ \"ถอยทัพเสแสร้ง\" โดยแกล้งทำตัวอ่อนน้อมและยอมจำนนต่อศัตรู ปล่อยให้พวกเขาลดความระมัดระ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Build FAISS Index\n",
        "def build_faiss_index(chunks):\n",
        "    \"\"\"\n",
        "    Build FAISS index for semantic retrieval\n",
        "    \"\"\"\n",
        "    if not chunks:\n",
        "        return None, None\n",
        "\n",
        "    # Extract chunk texts\n",
        "    chunk_texts = [chunk['chunk_text'] for chunk in chunks]\n",
        "\n",
        "    # Encode all chunks\n",
        "    embeddings = model.encode(chunk_texts)\n",
        "\n",
        "    # Normalize embeddings for cosine similarity\n",
        "    embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "\n",
        "    # Build FAISS index\n",
        "    dim = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatIP(dim)  # Inner Product for normalized vectors\n",
        "    index.add(embeddings.astype(np.float32))\n",
        "\n",
        "    return index, embeddings\n",
        "\n",
        "# Build FAISS index\n",
        "faiss_index, chunk_embeddings = build_faiss_index(all_chunks)\n",
        "if faiss_index is not None:\n",
        "    print(f\"FAISS index built with {faiss_index.ntotal} vectors\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJLThCQPrD_b",
        "outputId": "daf494a3-5064-4cb0-9275-8375b7fce071"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index built with 424 vectors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Semantic Retrieval Function\n",
        "def semantic_retrieval(query, index, chunks, top_k=5):\n",
        "    \"\"\"\n",
        "    Retrieve relevant chunks using FAISS\n",
        "    \"\"\"\n",
        "    if index is None or not chunks:\n",
        "        return []\n",
        "\n",
        "    # Encode query\n",
        "    query_embedding = model.encode([query])\n",
        "    query_embedding = query_embedding / np.linalg.norm(query_embedding, axis=1, keepdims=True)\n",
        "\n",
        "    # Search\n",
        "    scores, indices = index.search(query_embedding.astype(np.float32), top_k)\n",
        "\n",
        "    # Prepare results\n",
        "    results = []\n",
        "    for i, (score, idx) in enumerate(zip(scores[0], indices[0])):\n",
        "        results.append({\n",
        "            'chunk': chunks[idx],\n",
        "            'score': float(score),\n",
        "            'rank': i + 1\n",
        "        })\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "oBWWXz81rHXL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: TF-IDF Re-Ranking\n",
        "def tfidf_reranking(query, retrieved_chunks, alpha=0.7):\n",
        "    \"\"\"\n",
        "    Re-rank retrieved chunks using TF-IDF + semantic scores\n",
        "    \"\"\"\n",
        "    if not retrieved_chunks:\n",
        "        return []\n",
        "\n",
        "    # Prepare texts\n",
        "    texts = [query] + [chunk['chunk']['chunk_text'] for chunk in retrieved_chunks]\n",
        "\n",
        "    # Create TF-IDF matrix\n",
        "    vectorizer = TfidfVectorizer(max_features=1000, stop_words=None)\n",
        "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
        "\n",
        "    # Calculate TF-IDF similarities\n",
        "    query_tfidf = tfidf_matrix[0]\n",
        "    chunk_tfidf = tfidf_matrix[1:]\n",
        "\n",
        "    tfidf_similarities = cosine_similarity(query_tfidf, chunk_tfidf)[0]\n",
        "\n",
        "    # Combine scores\n",
        "    reranked_results = []\n",
        "    for i, result in enumerate(retrieved_chunks):\n",
        "        semantic_score = result['score']\n",
        "        tfidf_score = tfidf_similarities[i]\n",
        "\n",
        "        combined_score = alpha * semantic_score + (1 - alpha) * tfidf_score\n",
        "\n",
        "        reranked_results.append({\n",
        "            'chunk': result['chunk'],\n",
        "            'semantic_score': semantic_score,\n",
        "            'tfidf_score': tfidf_score,\n",
        "            'combined_score': combined_score,\n",
        "            'original_rank': result['rank']\n",
        "        })\n",
        "\n",
        "    # Sort by combined score\n",
        "    reranked_results.sort(key=lambda x: x['combined_score'], reverse=True)\n",
        "\n",
        "    # Update ranks\n",
        "    for i, result in enumerate(reranked_results):\n",
        "        result['new_rank'] = i + 1\n",
        "\n",
        "    return reranked_results"
      ],
      "metadata": {
        "id": "CeGs0iM-rI2F"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Updated 6C Framework Definitions\n",
        "# Updated 6C Framework in Thai\n",
        "sixc_definitions = {\n",
        "    'ความแข็งแกร่งในการรุก': (\n",
        "        'ความสามารถในการสร้างและเปลี่ยนแปลงภูมิทัศน์เชิงกลยุทธ์อย่างมีประสิทธิภาพ\\n'\n",
        "        'Offensive Strength: ความสามารถในการกำหนดทิศทางและเป็นฝ่ายรุกก่อน\\n'\n",
        "        'ตัวอย่าง: เดินหมากที่ดูธรรมดาในกลางกระดาน แต่เป็นการเปิดโอกาสให้บุกเข้ายึดมุมภายหลัง'\n",
        "    ),\n",
        "    'ความแข็งแกร่งในการป้องกัน': (\n",
        "        'ความสามารถในการตอบสนองต่อการกระทำหรือความท้าทายจากฝ่ายตรงข้ามได้อย่างมีประสิทธิภาพ\\n'\n",
        "        'Defensive Strength: ความสามารถในการตั้งรับและรักษาตำแหน่งเมื่อถูกโจมตี\\n'\n",
        "        'ตัวอย่าง: กดดันหมากตรงกลางให้แน่น แล้วถอยเข้ามาป้องกันกลุ่มที่ถูกล้อมไว้จนปลอดภัย'\n",
        "    ),\n",
        "    'ความสามารถในการสัมพันธ์': (\n",
        "        'ความสามารถในการจัดการและใช้ประโยชน์จากความสัมพันธ์กับผู้มีส่วนได้ส่วนเสียภายนอก\\n'\n",
        "        'Relational Capacity: ความสามารถใช้หมากรอบข้างช่วยเสริมกำลังกัน\\n'\n",
        "        'ตัวอย่าง: ล่อให้คู่ต่อสู้มาตัด แล้วใช้หมากรอบข้างพารวมกันทำแต้มจากมุมอื่น'\n",
        "    ),\n",
        "    'ศักยภาพที่มี': (\n",
        "        'การมีอยู่และการใช้ทรัพยากรอย่างมีกลยุทธ์\\n'\n",
        "        'Potential Energy: ศักยภาพหมากหรือพื้นที่ที่ยังไม่ได้ใช้อย่างเต็มที่\\n'\n",
        "        'ตัวอย่าง: กระโดดไปยังจุดว่าง เพื่อรอสร้างแนวหนาแล้วค่อยเคลื่อนหมากหลักเข้าสู่เกม'\n",
        "    ),\n",
        "    'ความพร้อมด้านเวลา': (\n",
        "        'การใช้เวลาที่เหมาะสมในการตัดสินใจ\\n'\n",
        "        'Temporal Availability: การเลือกจังหวะที่เหมาะสมในการเดินหมาก\\n'\n",
        "        'ตัวอย่าง: ฉวยโอกาสเดินหมากกลางกระดานขณะคู่ต่อสู้กำลังสับสน เพื่อเก็บแต้มก่อน'\n",
        "    ),\n",
        "    'ความเหมาะสมในบริบท': (\n",
        "        'ระดับที่การตัดสินใจสอดคล้องกับบริบทเชิงกลยุทธ์ ทำให้มีข้อมูลที่ถูกต้องและเกี่ยวข้อง\\n'\n",
        "        'Contextual Fit: ความเหมาะสมของการเดินหมากกับภาพรวมสถานการณ์\\n'\n",
        "        'ตัวอย่าง: ยั่วให้คู่ต่อสู้รับที่มุมบนก่อน แล้วย้ายหมากไปบุกมุมขวาล่างทันที'\n",
        "    ),\n",
        "}\n",
        "\n",
        "def compute_6c_embeddings():\n",
        "    \"\"\"\n",
        "    Compute embeddings for 6C definitions\n",
        "    \"\"\"\n",
        "    definitions = list(sixc_definitions.values())\n",
        "    embeddings = model.encode(definitions)\n",
        "    return embeddings\n",
        "\n",
        "def compute_6c_vector(text):\n",
        "    \"\"\"\n",
        "    Compute 6C vector for given text\n",
        "    \"\"\"\n",
        "    # Get 6C embeddings\n",
        "    sixc_embeddings = compute_6c_embeddings()\n",
        "\n",
        "    # Encode text\n",
        "    text_embedding = model.encode([text])\n",
        "\n",
        "    # Compute raw scores (dot product)\n",
        "    raw_scores = np.dot(text_embedding, sixc_embeddings.T)[0]\n",
        "\n",
        "    # Normalize to distribution\n",
        "    distribution = np.exp(raw_scores) / np.sum(np.exp(raw_scores))\n",
        "\n",
        "    return distribution\n",
        "\n",
        "# Test 6C vector computation\n",
        "test_text = \"ฉันต้องการหลอกลวงคู่แข่งให้เข้าใจผิด\"\n",
        "sixc_vector = compute_6c_vector(test_text)\n",
        "sixc_labels = list(sixc_definitions.keys())\n",
        "\n",
        "print(\"6C Vector for test text:\")\n",
        "for i, (label, score) in enumerate(zip(sixc_labels, sixc_vector)):\n",
        "    print(f\"{label}: {score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur-8YEbvrKXk",
        "outputId": "46b158dd-a056-439b-c664-94a1bac2d044"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6C Vector for test text:\n",
            "ความแข็งแกร่งในการรุก: 0.1591\n",
            "ความแข็งแกร่งในการป้องกัน: 0.1616\n",
            "ความสามารถในการสัมพันธ์: 0.1710\n",
            "ศักยภาพที่มี: 0.1641\n",
            "ความพร้อมด้านเวลา: 0.1709\n",
            "ความเหมาะสมในบริบท: 0.1733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Compute 6C Patterns for All Strategies\n",
        "def compute_all_strategy_patterns(df):\n",
        "    \"\"\"\n",
        "    Compute 6C patterns for all strategies\n",
        "    \"\"\"\n",
        "    if df is None:\n",
        "        return {}\n",
        "\n",
        "    patterns = {}\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        strategy_name = row['ชื่อกลยุทธ์']\n",
        "        full_text = f\"{row['ลักษณะ']} {row['ตัวอย่างกลยุทธ์']}\"\n",
        "\n",
        "        # Add Go example if available\n",
        "        if 'ตัวอย่างการเดินหมาก' in row and pd.notna(row['ตัวอย่างการเดินหมาก']):\n",
        "            full_text += f\" {row['ตัวอย่างการเดินหมาก']}\"\n",
        "\n",
        "        # Compute 6C vector\n",
        "        sixc_vector = compute_6c_vector(full_text)\n",
        "        patterns[strategy_name] = sixc_vector\n",
        "\n",
        "    return patterns\n",
        "\n",
        "# Compute patterns for all strategies\n",
        "strategy_patterns = compute_all_strategy_patterns(df)\n",
        "\n",
        "if strategy_patterns:\n",
        "    print(\"6C Patterns for all strategies:\")\n",
        "    for strategy, pattern in list(strategy_patterns.items())[:]:\n",
        "        print(f\"\\n{strategy}:\")\n",
        "        for i, (label, score) in enumerate(zip(sixc_labels, pattern)):\n",
        "            print(f\"  {label}: {score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxJGp6msrMO4",
        "outputId": "baf76d50-119e-4ec5-f80b-839110d10a05"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6C Patterns for all strategies:\n",
            "\n",
            "ปิดฟ้าข้ามทะเล:\n",
            "  ความแข็งแกร่งในการรุก: 0.1737\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1655\n",
            "  ความสามารถในการสัมพันธ์: 0.1566\n",
            "  ศักยภาพที่มี: 0.1673\n",
            "  ความพร้อมด้านเวลา: 0.1631\n",
            "  ความเหมาะสมในบริบท: 0.1739\n",
            "\n",
            "ล้อมเว่ยช่วยจ้าว:\n",
            "  ความแข็งแกร่งในการรุก: 0.1714\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1613\n",
            "  ความสามารถในการสัมพันธ์: 0.1583\n",
            "  ศักยภาพที่มี: 0.1659\n",
            "  ความพร้อมด้านเวลา: 0.1641\n",
            "  ความเหมาะสมในบริบท: 0.1789\n",
            "\n",
            "ยืมดาบฆ่าคน:\n",
            "  ความแข็งแกร่งในการรุก: 0.1651\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1603\n",
            "  ความสามารถในการสัมพันธ์: 0.1672\n",
            "  ศักยภาพที่มี: 0.1658\n",
            "  ความพร้อมด้านเวลา: 0.1662\n",
            "  ความเหมาะสมในบริบท: 0.1754\n",
            "\n",
            "รอซ้ำยามเปลี้ย:\n",
            "  ความแข็งแกร่งในการรุก: 0.1712\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1597\n",
            "  ความสามารถในการสัมพันธ์: 0.1537\n",
            "  ศักยภาพที่มี: 0.1663\n",
            "  ความพร้อมด้านเวลา: 0.1711\n",
            "  ความเหมาะสมในบริบท: 0.1780\n",
            "\n",
            "ชิงซ้ำตามไฟ:\n",
            "  ความแข็งแกร่งในการรุก: 0.1672\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1589\n",
            "  ความสามารถในการสัมพันธ์: 0.1622\n",
            "  ศักยภาพที่มี: 0.1686\n",
            "  ความพร้อมด้านเวลา: 0.1695\n",
            "  ความเหมาะสมในบริบท: 0.1735\n",
            "\n",
            "ส่งเสียงบูรพาตีประจิม:\n",
            "  ความแข็งแกร่งในการรุก: 0.1658\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1683\n",
            "  ความสามารถในการสัมพันธ์: 0.1567\n",
            "  ศักยภาพที่มี: 0.1676\n",
            "  ความพร้อมด้านเวลา: 0.1674\n",
            "  ความเหมาะสมในบริบท: 0.1742\n",
            "\n",
            "มีในไม่มี:\n",
            "  ความแข็งแกร่งในการรุก: 0.1665\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1529\n",
            "  ความสามารถในการสัมพันธ์: 0.1611\n",
            "  ศักยภาพที่มี: 0.1711\n",
            "  ความพร้อมด้านเวลา: 0.1677\n",
            "  ความเหมาะสมในบริบท: 0.1806\n",
            "\n",
            "ลอบตีเฉินชาง:\n",
            "  ความแข็งแกร่งในการรุก: 0.1670\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1624\n",
            "  ความสามารถในการสัมพันธ์: 0.1599\n",
            "  ศักยภาพที่มี: 0.1672\n",
            "  ความพร้อมด้านเวลา: 0.1700\n",
            "  ความเหมาะสมในบริบท: 0.1735\n",
            "\n",
            "ดูไฟชายฝั่ง:\n",
            "  ความแข็งแกร่งในการรุก: 0.1742\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1600\n",
            "  ความสามารถในการสัมพันธ์: 0.1574\n",
            "  ศักยภาพที่มี: 0.1634\n",
            "  ความพร้อมด้านเวลา: 0.1688\n",
            "  ความเหมาะสมในบริบท: 0.1761\n",
            "\n",
            "ซ่อนดาบบนรอยยิ้ม:\n",
            "  ความแข็งแกร่งในการรุก: 0.1654\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1581\n",
            "  ความสามารถในการสัมพันธ์: 0.1688\n",
            "  ศักยภาพที่มี: 0.1625\n",
            "  ความพร้อมด้านเวลา: 0.1661\n",
            "  ความเหมาะสมในบริบท: 0.1791\n",
            "\n",
            "หลีตายแทนถาว:\n",
            "  ความแข็งแกร่งในการรุก: 0.1652\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1546\n",
            "  ความสามารถในการสัมพันธ์: 0.1669\n",
            "  ศักยภาพที่มี: 0.1718\n",
            "  ความพร้อมด้านเวลา: 0.1661\n",
            "  ความเหมาะสมในบริบท: 0.1753\n",
            "\n",
            "จูงแพะติดมือ:\n",
            "  ความแข็งแกร่งในการรุก: 0.1667\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1579\n",
            "  ความสามารถในการสัมพันธ์: 0.1618\n",
            "  ศักยภาพที่มี: 0.1663\n",
            "  ความพร้อมด้านเวลา: 0.1694\n",
            "  ความเหมาะสมในบริบท: 0.1780\n",
            "\n",
            "ตีหญ้าให้งูตื่น:\n",
            "  ความแข็งแกร่งในการรุก: 0.1671\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1627\n",
            "  ความสามารถในการสัมพันธ์: 0.1552\n",
            "  ศักยภาพที่มี: 0.1665\n",
            "  ความพร้อมด้านเวลา: 0.1701\n",
            "  ความเหมาะสมในบริบท: 0.1784\n",
            "\n",
            "ยืมซากคืนชีพ:\n",
            "  ความแข็งแกร่งในการรุก: 0.1666\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1595\n",
            "  ความสามารถในการสัมพันธ์: 0.1648\n",
            "  ศักยภาพที่มี: 0.1718\n",
            "  ความพร้อมด้านเวลา: 0.1664\n",
            "  ความเหมาะสมในบริบท: 0.1709\n",
            "\n",
            "ล่อเสือออกจากถ้ำ:\n",
            "  ความแข็งแกร่งในการรุก: 0.1730\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1584\n",
            "  ความสามารถในการสัมพันธ์: 0.1660\n",
            "  ศักยภาพที่มี: 0.1687\n",
            "  ความพร้อมด้านเวลา: 0.1616\n",
            "  ความเหมาะสมในบริบท: 0.1723\n",
            "\n",
            "แสร้งปล่อยเพื่อจับ:\n",
            "  ความแข็งแกร่งในการรุก: 0.1675\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1622\n",
            "  ความสามารถในการสัมพันธ์: 0.1672\n",
            "  ศักยภาพที่มี: 0.1648\n",
            "  ความพร้อมด้านเวลา: 0.1663\n",
            "  ความเหมาะสมในบริบท: 0.1720\n",
            "\n",
            "โยนกระเบื้องล่อหยก:\n",
            "  ความแข็งแกร่งในการรุก: 0.1718\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1553\n",
            "  ความสามารถในการสัมพันธ์: 0.1688\n",
            "  ศักยภาพที่มี: 0.1674\n",
            "  ความพร้อมด้านเวลา: 0.1612\n",
            "  ความเหมาะสมในบริบท: 0.1756\n",
            "\n",
            "จับโจรเอาหัวโจก:\n",
            "  ความแข็งแกร่งในการรุก: 0.1709\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1582\n",
            "  ความสามารถในการสัมพันธ์: 0.1601\n",
            "  ศักยภาพที่มี: 0.1699\n",
            "  ความพร้อมด้านเวลา: 0.1639\n",
            "  ความเหมาะสมในบริบท: 0.1769\n",
            "\n",
            "ถอนฟืนใต้กระทะ:\n",
            "  ความแข็งแกร่งในการรุก: 0.1689\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1673\n",
            "  ความสามารถในการสัมพันธ์: 0.1589\n",
            "  ศักยภาพที่มี: 0.1677\n",
            "  ความพร้อมด้านเวลา: 0.1644\n",
            "  ความเหมาะสมในบริบท: 0.1729\n",
            "\n",
            "กวนน้ำจับปลา:\n",
            "  ความแข็งแกร่งในการรุก: 0.1722\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1597\n",
            "  ความสามารถในการสัมพันธ์: 0.1587\n",
            "  ศักยภาพที่มี: 0.1667\n",
            "  ความพร้อมด้านเวลา: 0.1716\n",
            "  ความเหมาะสมในบริบท: 0.1710\n",
            "\n",
            "จักจั่นลอกคราบ:\n",
            "  ความแข็งแกร่งในการรุก: 0.1697\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1665\n",
            "  ความสามารถในการสัมพันธ์: 0.1603\n",
            "  ศักยภาพที่มี: 0.1688\n",
            "  ความพร้อมด้านเวลา: 0.1620\n",
            "  ความเหมาะสมในบริบท: 0.1728\n",
            "\n",
            "ปิดประตูจับโจร:\n",
            "  ความแข็งแกร่งในการรุก: 0.1688\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1731\n",
            "  ความสามารถในการสัมพันธ์: 0.1600\n",
            "  ศักยภาพที่มี: 0.1645\n",
            "  ความพร้อมด้านเวลา: 0.1630\n",
            "  ความเหมาะสมในบริบท: 0.1706\n",
            "\n",
            "คบไกลตีใกล้:\n",
            "  ความแข็งแกร่งในการรุก: 0.1664\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1631\n",
            "  ความสามารถในการสัมพันธ์: 0.1641\n",
            "  ศักยภาพที่มี: 0.1659\n",
            "  ความพร้อมด้านเวลา: 0.1624\n",
            "  ความเหมาะสมในบริบท: 0.1782\n",
            "\n",
            "ยืมทางพรางกล:\n",
            "  ความแข็งแกร่งในการรุก: 0.1629\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1650\n",
            "  ความสามารถในการสัมพันธ์: 0.1648\n",
            "  ศักยภาพที่มี: 0.1619\n",
            "  ความพร้อมด้านเวลา: 0.1666\n",
            "  ความเหมาะสมในบริบท: 0.1788\n",
            "\n",
            "ลักชื่อเปลี่ยนเสา:\n",
            "  ความแข็งแกร่งในการรุก: 0.1752\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1609\n",
            "  ความสามารถในการสัมพันธ์: 0.1612\n",
            "  ศักยภาพที่มี: 0.1696\n",
            "  ความพร้อมด้านเวลา: 0.1618\n",
            "  ความเหมาะสมในบริบท: 0.1713\n",
            "\n",
            "ต้นหม่อนด่าต้นไหว:\n",
            "  ความแข็งแกร่งในการรุก: 0.1749\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1710\n",
            "  ความสามารถในการสัมพันธ์: 0.1708\n",
            "  ศักยภาพที่มี: 0.1619\n",
            "  ความพร้อมด้านเวลา: 0.1525\n",
            "  ความเหมาะสมในบริบท: 0.1690\n",
            "\n",
            "แสร้งทำบอแต่ไม่บ้า:\n",
            "  ความแข็งแกร่งในการรุก: 0.1717\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1658\n",
            "  ความสามารถในการสัมพันธ์: 0.1612\n",
            "  ศักยภาพที่มี: 0.1646\n",
            "  ความพร้อมด้านเวลา: 0.1650\n",
            "  ความเหมาะสมในบริบท: 0.1717\n",
            "\n",
            "ขึ้นบ้านชักบันได:\n",
            "  ความแข็งแกร่งในการรุก: 0.1700\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1652\n",
            "  ความสามารถในการสัมพันธ์: 0.1616\n",
            "  ศักยภาพที่มี: 0.1666\n",
            "  ความพร้อมด้านเวลา: 0.1630\n",
            "  ความเหมาะสมในบริบท: 0.1736\n",
            "\n",
            "ต้นไม้ผลิตอก:\n",
            "  ความแข็งแกร่งในการรุก: 0.1685\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1620\n",
            "  ความสามารถในการสัมพันธ์: 0.1650\n",
            "  ศักยภาพที่มี: 0.1732\n",
            "  ความพร้อมด้านเวลา: 0.1626\n",
            "  ความเหมาะสมในบริบท: 0.1687\n",
            "\n",
            "สลับแขกเป็นเจ้าบ้าน:\n",
            "  ความแข็งแกร่งในการรุก: 0.1716\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1593\n",
            "  ความสามารถในการสัมพันธ์: 0.1593\n",
            "  ศักยภาพที่มี: 0.1618\n",
            "  ความพร้อมด้านเวลา: 0.1696\n",
            "  ความเหมาะสมในบริบท: 0.1784\n",
            "\n",
            "สาวงาม:\n",
            "  ความแข็งแกร่งในการรุก: 0.1742\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1613\n",
            "  ความสามารถในการสัมพันธ์: 0.1621\n",
            "  ศักยภาพที่มี: 0.1719\n",
            "  ความพร้อมด้านเวลา: 0.1590\n",
            "  ความเหมาะสมในบริบท: 0.1716\n",
            "\n",
            "ปิดเมือง:\n",
            "  ความแข็งแกร่งในการรุก: 0.1747\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1693\n",
            "  ความสามารถในการสัมพันธ์: 0.1601\n",
            "  ศักยภาพที่มี: 0.1650\n",
            "  ความพร้อมด้านเวลา: 0.1588\n",
            "  ความเหมาะสมในบริบท: 0.1723\n",
            "\n",
            "ไส้ศึก:\n",
            "  ความแข็งแกร่งในการรุก: 0.1715\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1635\n",
            "  ความสามารถในการสัมพันธ์: 0.1670\n",
            "  ศักยภาพที่มี: 0.1616\n",
            "  ความพร้อมด้านเวลา: 0.1626\n",
            "  ความเหมาะสมในบริบท: 0.1739\n",
            "\n",
            "ตีเรืออับปาง:\n",
            "  ความแข็งแกร่งในการรุก: 0.1750\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1692\n",
            "  ความสามารถในการสัมพันธ์: 0.1570\n",
            "  ศักยภาพที่มี: 0.1686\n",
            "  ความพร้อมด้านเวลา: 0.1604\n",
            "  ความเหมาะสมในบริบท: 0.1699\n",
            "\n",
            "เรือนว่าง:\n",
            "  ความแข็งแกร่งในการรุก: 0.1726\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1620\n",
            "  ความสามารถในการสัมพันธ์: 0.1555\n",
            "  ศักยภาพที่มี: 0.1743\n",
            "  ความพร้อมด้านเวลา: 0.1643\n",
            "  ความเหมาะสมในบริบท: 0.1713\n",
            "\n",
            "บาดเจ็บยอมได้:\n",
            "  ความแข็งแกร่งในการรุก: 0.1660\n",
            "  ความแข็งแกร่งในการป้องกัน: 0.1633\n",
            "  ความสามารถในการสัมพันธ์: 0.1663\n",
            "  ศักยภาพที่มี: 0.1673\n",
            "  ความพร้อมด้านเวลา: 0.1629\n",
            "  ความเหมาะสมในบริบท: 0.1742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: KL Divergence Matching\n",
        "def kl_divergence(p, q, epsilon=1e-10):\n",
        "    \"\"\"\n",
        "    Compute KL divergence between two distributions\n",
        "    D_KL(p || q) = sum(p * log(p / q))\n",
        "    \"\"\"\n",
        "    # Add small epsilon to avoid log(0)\n",
        "    q = q + epsilon\n",
        "    p = p + epsilon\n",
        "\n",
        "    # Renormalize\n",
        "    p = p / np.sum(p)\n",
        "    q = q / np.sum(q)\n",
        "\n",
        "    return np.sum(p * np.log(p / q))\n",
        "\n",
        "def match_strategies_kl(situation_text, strategy_patterns, top_k=3):\n",
        "    \"\"\"\n",
        "    Match situation with strategies using KL divergence\n",
        "    \"\"\"\n",
        "    if not strategy_patterns:\n",
        "        return []\n",
        "\n",
        "    # Compute 6C vector for situation\n",
        "    situation_vector = compute_6c_vector(situation_text)\n",
        "\n",
        "    # Compute KL divergence for each strategy\n",
        "    kl_scores = []\n",
        "    for strategy_name, strategy_vector in strategy_patterns.items():\n",
        "        kl_score = kl_divergence(situation_vector, strategy_vector)\n",
        "        kl_scores.append((strategy_name, kl_score))\n",
        "\n",
        "    # Sort by KL divergence (lower is better)\n",
        "    kl_scores.sort(key=lambda x: x[1])\n",
        "\n",
        "    return kl_scores[:top_k]\n"
      ],
      "metadata": {
        "id": "oLzEzBx9rN-5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Structured Analysis Function (No LLM)\n",
        "def generate_structured_analysis(situation, top_strategies, retrieved_chunks):\n",
        "    \"\"\"\n",
        "    Generate structured analysis without LLM\n",
        "    \"\"\"\n",
        "    # Compute 6C vector for situation\n",
        "    situation_vector = compute_6c_vector(situation)\n",
        "\n",
        "    # Prepare context chunks\n",
        "    context_chunks = []\n",
        "    for i, result in enumerate(retrieved_chunks[:3]):\n",
        "        context_chunks.append(f\"[ref{i+1}] {result['chunk']['strategy_name']}: {result['chunk']['chunk_text']}\")\n",
        "\n",
        "    context = \"\\n\".join(context_chunks)\n",
        "\n",
        "    # Prepare strategy ranking\n",
        "    strategy_ranking = []\n",
        "    for i, (strategy, kl_score) in enumerate(top_strategies):\n",
        "        strategy_ranking.append(f\"{i+1}. {strategy} (KL: {kl_score:.6f})\")\n",
        "\n",
        "    ranking_text = \"\\n\".join(strategy_ranking)\n",
        "\n",
        "    # Generate structured analysis\n",
        "    analysis = f\"\"\"**PLAN:**\n",
        "Step 1: วิเคราะห์องค์ประกอบหลักของสถานการณ์\n",
        "Step 2: ประเมิน 6C Framework ในบริบทของสถานการณ์\n",
        "Step 3: วิเคราะห์คะแนน KL Divergence และความหมาย\n",
        "Step 4: เชื่อมโยงกับข้อมูลประวัติศาสตร์\n",
        "Step 5: สรุปกลยุทธ์ที่แนะนำ\n",
        "\n",
        "**STEP 1**\n",
        "**Title:** วิเคราะห์องค์ประกอบหลักของสถานการณ์\n",
        "**Summary:** ระบุตัวละคร เป้าหมาย และแรงจูงใจในสถานการณ์: \"{situation}\"\n",
        "\n",
        "**STEP 2**\n",
        "**Title:** ประเมิน 6C Framework ในบริบทของสถานการณ์\n",
        "**Summary:** การประเมิน 6C Framework สำหรับสถานการณ์นี้:\n",
        "\"\"\"\n",
        "\n",
        "    # Add 6C analysis\n",
        "    for i, (label, score) in enumerate(zip(sixc_labels, situation_vector)):\n",
        "        level = \"สูง\" if score > 0.2 else \"กลาง\" if score > 0.15 else \"ต่ำ\"\n",
        "        analysis += f\"\\n- {label}: {score:.4f} ({level})\"\n",
        "\n",
        "    analysis += f\"\"\"\n",
        "\n",
        "**STEP 3**\n",
        "**Title:** วิเคราะห์คะแนน KL Divergence และความหมาย\n",
        "**Summary:** คะแนน KL ต่ำหมายถึงความคล้ายคลึงสูงระหว่างรูปแบบ 6C ของสถานการณ์กับกลยุทธ์\n",
        "{ranking_text}\n",
        "\n",
        "**STEP 4**\n",
        "**Title:** เชื่อมโยงกับข้อมูลประวัติศาสตร์\n",
        "**Summary:** ข้อมูลประวัติศาสตร์ที่เกี่ยวข้อง:\n",
        "{context}\n",
        "\n",
        "**STEP 5**\n",
        "**Title:** สรุปกลยุทธ์ที่แนะนำ\n",
        "**Summary:** ให้คำแนะนำกลยุทธ์ที่ครอบคลุมและปฏิบัติได้\n",
        "\n",
        "**RESPONSE:**\n",
        "### **การวิเคราะห์สถานการณ์:**\n",
        "สถานการณ์: \"{situation}\"\n",
        "\n",
        "องค์ประกอบหลัก: การแลกเปลี่ยนและการได้มาซึ่งทรัพยากรมนุษย์ที่มีคุณค่า ซึ่งเกี่ยวข้องกับการตัดสินใจเชิงกลยุทธ์ที่ต้องชั่งน้ำหนักระหว่างการสูญเสียและการได้รับ\n",
        "\n",
        "### **การประเมิน 6C Framework:**\n",
        "\"\"\"\n",
        "\n",
        "    for i, (label, score) in enumerate(zip(sixc_labels, situation_vector)):\n",
        "        level = \"สูง\" if score > 0.2 else \"กลาง\" if score > 0.15 else \"ต่ำ\"\n",
        "        analysis += f\"\\n{i+1}. **{label}:** {score:.4f} ({level})\"\n",
        "\n",
        "    analysis += f\"\"\"\n",
        "\n",
        "### **กลยุทธ์ที่แนะนำ:**\n",
        "**อันดับ 1:** {top_strategies[0][0]} (KL: {top_strategies[0][1]:.6f})\n",
        "- มีรูปแบบ 6C ที่สอดคล้องกับสถานการณ์มากที่สุด\n",
        "- เหมาะสำหรับการจัดการความซับซ้อนและการตัดสินใจเชิงกลยุทธ์\n",
        "\n",
        "**อันดับ 2:** {top_strategies[1][0]} (KL: {top_strategies[1][1]:.6f})\n",
        "- เป็นกลยุทธ์สำรองที่มีความเหมาะสมสูง\n",
        "- สามารถนำมาใช้ร่วมกับกลยุทธ์หลัก\n",
        "\n",
        "**อันดับ 3:** {top_strategies[2][0]} (KL: {top_strategies[2][1]:.6f})\n",
        "- เป็นทางเลือกที่ควรพิจารณาเป็นแผนสำรอง\n",
        "- เหมาะสำหรับสถานการณ์ที่ซับซ้อนขึ้น\n",
        "\n",
        "### **ข้อมูลสนับสนุนจากประวัติศาสตร์:**\n",
        "{context}\n",
        "\n",
        "### **คำแนะนำการประยุกต์ใช้:**\n",
        "ควรพิจารณาใช้กลยุทธ์อันดับ 1 เป็นหลัก โดยเน้นการสร้างความสมดุลระหว่างการให้และการรับ\n",
        "และเตรียมกลยุทธ์สำรองจากอันดับ 2-3 เพื่อรองรับสถานการณ์ที่อาจเปลี่ยนแปลง\n",
        "การตัดสินใจควรคำนึงถึงผลกระทบระยะยาวและความสัมพันธ์กับฝ่ายต่างๆ\"\"\"\n",
        "\n",
        "    return analysis"
      ],
      "metadata": {
        "id": "2UMgFfENrQb0"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: Main Analysis Function\n",
        "def analyze_situation(situation):\n",
        "    \"\"\"\n",
        "    วิเคราะห์สถานการณ์โดยไม่ใช้ LLM\n",
        "    \"\"\"\n",
        "    print(f\"=== การวิเคราะห์สถานการณ์ ===\")\n",
        "    print(f\"สถานการณ์: {situation}\")\n",
        "    print()\n",
        "\n",
        "    # Step 1: Semantic Retrieval\n",
        "    print(\"1. Semantic Retrieval...\")\n",
        "    retrieval_results = semantic_retrieval(situation, faiss_index, all_chunks, top_k=5)\n",
        "\n",
        "    # Step 2: TF-IDF Re-ranking\n",
        "    print(\"2. TF-IDF Re-ranking...\")\n",
        "    reranked_results = tfidf_reranking(situation, retrieval_results)\n",
        "\n",
        "    # Step 3: 6C + KL Matching\n",
        "    print(\"3. 6C + KL Matching...\")\n",
        "    top_strategies = match_strategies_kl(situation, strategy_patterns, top_k=3)\n",
        "\n",
        "    # Step 4: Generate Structured Analysis\n",
        "    print(\"4. Generating Structured Analysis...\")\n",
        "    structured_analysis = generate_structured_analysis(situation, top_strategies, reranked_results)\n",
        "\n",
        "    print(\"\\n=== ผลลัพธ์การวิเคราะห์ ===\")\n",
        "    print(\"Top 3 กลยุทธ์ที่ใกล้เคียงที่สุด:\")\n",
        "    for i, (strategy, kl_score) in enumerate(top_strategies):\n",
        "        print(f\"{i+1}. {strategy} (KL Divergence: {kl_score:.4f})\")\n",
        "\n",
        "    print(\"\\nข้อความที่เกี่ยวข้อง (TF-IDF + Semantic):\")\n",
        "    for result in reranked_results[:3]:\n",
        "        print(f\"- {result['chunk']['strategy_name']} | คะแนนรวม: {result['combined_score']:.4f}\")\n",
        "        print(f\"  ข้อความ: {result['chunk']['chunk_text'][:100]}...\")\n",
        "        print()\n",
        "\n",
        "    print(\"\\n=== การวิเคราะห์แบบมีโครงสร้าง ===\")\n",
        "    print(structured_analysis)\n",
        "\n",
        "    return {\n",
        "        'situation': situation,\n",
        "        'retrieved_chunks': reranked_results,\n",
        "        'top_strategies': top_strategies,\n",
        "        'structured_analysis': structured_analysis\n",
        "    }\n",
        "\n",
        "# Test the system\n",
        "if df is not None and faiss_index is not None:\n",
        "    test_situation = \"จูกัดเหลียงที่พึงพอใจฝีมือเกียงอุยจึงอยากได้ตัวไว้ จึงยอมเสียแฮหัวหลิมซึ่งมีตำแหน่งเป็นถึงบุตรเขยของโจยอยเพียงเพื่อให้ได้มาซึ่งนายทหารที่มีสติปัญญาเป็นเลิศ\"\n",
        "    results = analyze_situation(test_situation)\n",
        "else:\n",
        "    print(\"Cannot run test - missing data or index\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uktru8_frR-2",
        "outputId": "5ed68219-0422-4ac2-a838-1aa4fd11feae"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== การวิเคราะห์สถานการณ์ ===\n",
            "สถานการณ์: จูกัดเหลียงที่พึงพอใจฝีมือเกียงอุยจึงอยากได้ตัวไว้ จึงยอมเสียแฮหัวหลิมซึ่งมีตำแหน่งเป็นถึงบุตรเขยของโจยอยเพียงเพื่อให้ได้มาซึ่งนายทหารที่มีสติปัญญาเป็นเลิศ\n",
            "\n",
            "1. Semantic Retrieval...\n",
            "2. TF-IDF Re-ranking...\n",
            "3. 6C + KL Matching...\n",
            "4. Generating Structured Analysis...\n",
            "\n",
            "=== ผลลัพธ์การวิเคราะห์ ===\n",
            "Top 3 กลยุทธ์ที่ใกล้เคียงที่สุด:\n",
            "1. หลีตายแทนถาว (KL Divergence: 0.0002)\n",
            "2. ยืมดาบฆ่าคน (KL Divergence: 0.0002)\n",
            "3. ซ่อนดาบบนรอยยิ้ม (KL Divergence: 0.0002)\n",
            "\n",
            "ข้อความที่เกี่ยวข้อง (TF-IDF + Semantic):\n",
            "- โยนกระเบื้องล่อหยก | คะแนนรวม: 0.7999\n",
            "  ข้อความ: ฝีมือเกียงอุยจึงอยากได้ตัวไว้ จึงยอมเสียหัวหลิมซึ่งมีตำแหน่งเป็นถึงบุตรเขยของโจโฉเพียงเพื่อให้ได้มาซ...\n",
            "\n",
            "- ตีเรืออับปาง | คะแนนรวม: 0.4044\n",
            "  ข้อความ: นำเอากลยุทธ์ตีเรืออับปางไปใช้ได้แก่ ขงเบ้งที่วางกลอุบายให้เตงงายหลงเชื่อว่าเป็นบุตรของจูกัดเกี๋ยม เพ...\n",
            "\n",
            "- มีในไม่มี | คะแนนรวม: 0.3868\n",
            "  ข้อความ: จึงฉวยโอกาสที่กำลังทหารของโจโฉกำลังเศร้าโศกเสียใจและไว้ทุกข์ให้แก่โจโฉ นำทัพไปเพื่อหวังตีทัพวุยก๊กแล...\n",
            "\n",
            "\n",
            "=== การวิเคราะห์แบบมีโครงสร้าง ===\n",
            "**PLAN:**\n",
            "Step 1: วิเคราะห์องค์ประกอบหลักของสถานการณ์\n",
            "Step 2: ประเมิน 6C Framework ในบริบทของสถานการณ์\n",
            "Step 3: วิเคราะห์คะแนน KL Divergence และความหมาย\n",
            "Step 4: เชื่อมโยงกับข้อมูลประวัติศาสตร์\n",
            "Step 5: สรุปกลยุทธ์ที่แนะนำ\n",
            "\n",
            "**STEP 1**\n",
            "**Title:** วิเคราะห์องค์ประกอบหลักของสถานการณ์\n",
            "**Summary:** ระบุตัวละคร เป้าหมาย และแรงจูงใจในสถานการณ์: \"จูกัดเหลียงที่พึงพอใจฝีมือเกียงอุยจึงอยากได้ตัวไว้ จึงยอมเสียแฮหัวหลิมซึ่งมีตำแหน่งเป็นถึงบุตรเขยของโจยอยเพียงเพื่อให้ได้มาซึ่งนายทหารที่มีสติปัญญาเป็นเลิศ\"\n",
            "\n",
            "**STEP 2**\n",
            "**Title:** ประเมิน 6C Framework ในบริบทของสถานการณ์\n",
            "**Summary:** การประเมิน 6C Framework สำหรับสถานการณ์นี้:\n",
            "\n",
            "- ความแข็งแกร่งในการรุก: 0.1598 (กลาง)\n",
            "- ความแข็งแกร่งในการป้องกัน: 0.1566 (กลาง)\n",
            "- ความสามารถในการสัมพันธ์: 0.1683 (กลาง)\n",
            "- ศักยภาพที่มี: 0.1687 (กลาง)\n",
            "- ความพร้อมด้านเวลา: 0.1681 (กลาง)\n",
            "- ความเหมาะสมในบริบท: 0.1785 (กลาง)\n",
            "\n",
            "**STEP 3**\n",
            "**Title:** วิเคราะห์คะแนน KL Divergence และความหมาย\n",
            "**Summary:** คะแนน KL ต่ำหมายถึงความคล้ายคลึงสูงระหว่างรูปแบบ 6C ของสถานการณ์กับกลยุทธ์\n",
            "1. หลีตายแทนถาว (KL: 0.000179)\n",
            "2. ยืมดาบฆ่าคน (KL: 0.000193)\n",
            "3. ซ่อนดาบบนรอยยิ้ม (KL: 0.000238)\n",
            "\n",
            "**STEP 4**\n",
            "**Title:** เชื่อมโยงกับข้อมูลประวัติศาสตร์\n",
            "**Summary:** ข้อมูลประวัติศาสตร์ที่เกี่ยวข้อง:\n",
            "[ref1] โยนกระเบื้องล่อหยก: ฝีมือเกียงอุยจึงอยากได้ตัวไว้ จึงยอมเสียหัวหลิมซึ่งมีตำแหน่งเป็นถึงบุตรเขยของโจโฉเพียงเพื่อให้ได้มาซึ่ง\n",
            "[ref2] ตีเรืออับปาง: นำเอากลยุทธ์ตีเรืออับปางไปใช้ได้แก่ ขงเบ้งที่วางกลอุบายให้เตงงายหลงเชื่อว่าเป็นบุตรของจูกัดเกี๋ยม เพื่อ\n",
            "[ref3] มีในไม่มี: จึงฉวยโอกาสที่กำลังทหารของโจโฉกำลังเศร้าโศกเสียใจและไว้ทุกข์ให้แก่โจโฉ นำทัพไปเพื่อหวังตีทัพวุยก๊กและ\n",
            "\n",
            "**STEP 5**\n",
            "**Title:** สรุปกลยุทธ์ที่แนะนำ\n",
            "**Summary:** ให้คำแนะนำกลยุทธ์ที่ครอบคลุมและปฏิบัติได้\n",
            "\n",
            "**RESPONSE:**\n",
            "### **การวิเคราะห์สถานการณ์:**\n",
            "สถานการณ์: \"จูกัดเหลียงที่พึงพอใจฝีมือเกียงอุยจึงอยากได้ตัวไว้ จึงยอมเสียแฮหัวหลิมซึ่งมีตำแหน่งเป็นถึงบุตรเขยของโจยอยเพียงเพื่อให้ได้มาซึ่งนายทหารที่มีสติปัญญาเป็นเลิศ\"\n",
            "\n",
            "องค์ประกอบหลัก: การแลกเปลี่ยนและการได้มาซึ่งทรัพยากรมนุษย์ที่มีคุณค่า ซึ่งเกี่ยวข้องกับการตัดสินใจเชิงกลยุทธ์ที่ต้องชั่งน้ำหนักระหว่างการสูญเสียและการได้รับ\n",
            "\n",
            "### **การประเมิน 6C Framework:**\n",
            "\n",
            "1. **ความแข็งแกร่งในการรุก:** 0.1598 (กลาง)\n",
            "2. **ความแข็งแกร่งในการป้องกัน:** 0.1566 (กลาง)\n",
            "3. **ความสามารถในการสัมพันธ์:** 0.1683 (กลาง)\n",
            "4. **ศักยภาพที่มี:** 0.1687 (กลาง)\n",
            "5. **ความพร้อมด้านเวลา:** 0.1681 (กลาง)\n",
            "6. **ความเหมาะสมในบริบท:** 0.1785 (กลาง)\n",
            "\n",
            "### **กลยุทธ์ที่แนะนำ:**\n",
            "**อันดับ 1:** หลีตายแทนถาว (KL: 0.000179)\n",
            "- มีรูปแบบ 6C ที่สอดคล้องกับสถานการณ์มากที่สุด\n",
            "- เหมาะสำหรับการจัดการความซับซ้อนและการตัดสินใจเชิงกลยุทธ์\n",
            "\n",
            "**อันดับ 2:** ยืมดาบฆ่าคน (KL: 0.000193)\n",
            "- เป็นกลยุทธ์สำรองที่มีความเหมาะสมสูง\n",
            "- สามารถนำมาใช้ร่วมกับกลยุทธ์หลัก\n",
            "\n",
            "**อันดับ 3:** ซ่อนดาบบนรอยยิ้ม (KL: 0.000238)\n",
            "- เป็นทางเลือกที่ควรพิจารณาเป็นแผนสำรอง\n",
            "- เหมาะสำหรับสถานการณ์ที่ซับซ้อนขึ้น\n",
            "\n",
            "### **ข้อมูลสนับสนุนจากประวัติศาสตร์:**\n",
            "[ref1] โยนกระเบื้องล่อหยก: ฝีมือเกียงอุยจึงอยากได้ตัวไว้ จึงยอมเสียหัวหลิมซึ่งมีตำแหน่งเป็นถึงบุตรเขยของโจโฉเพียงเพื่อให้ได้มาซึ่ง\n",
            "[ref2] ตีเรืออับปาง: นำเอากลยุทธ์ตีเรืออับปางไปใช้ได้แก่ ขงเบ้งที่วางกลอุบายให้เตงงายหลงเชื่อว่าเป็นบุตรของจูกัดเกี๋ยม เพื่อ\n",
            "[ref3] มีในไม่มี: จึงฉวยโอกาสที่กำลังทหารของโจโฉกำลังเศร้าโศกเสียใจและไว้ทุกข์ให้แก่โจโฉ นำทัพไปเพื่อหวังตีทัพวุยก๊กและ\n",
            "\n",
            "### **คำแนะนำการประยุกต์ใช้:**\n",
            "ควรพิจารณาใช้กลยุทธ์อันดับ 1 เป็นหลัก โดยเน้นการสร้างความสมดุลระหว่างการให้และการรับ\n",
            "และเตรียมกลยุทธ์สำรองจากอันดับ 2-3 เพื่อรองรับสถานการณ์ที่อาจเปลี่ยนแปลง\n",
            "การตัดสินใจควรคำนึงถึงผลกระทบระยะยาวและความสัมพันธ์กับฝ่ายต่างๆ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gqfQXoif_R6v"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}